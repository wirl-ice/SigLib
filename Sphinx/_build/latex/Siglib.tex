% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,openany,oneside]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}

\usepackage[english]{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}
\usepackage{eqparbox}


\addto\captionsenglish{\renewcommand{\figurename}{Fig. }}
\addto\captionsenglish{\renewcommand{\tablename}{Table }}
\SetupFloatingEnvironment{literal-block}{name=Listing }



\title{SigLib Documentation}
\date{August 08, 2019}
\release{2.8}
\author{D. Mueller, C. Lopes, S. Bouh-Ali, C. Fitzpatrick}
\newcommand{\sphinxlogo}{\includegraphics{wirl_logo.jpg}\par}
\renewcommand{\releasename}{Release}

\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ch\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@mb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@cpf\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\renewcommand\PYGZsq{\textquotesingle}

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}



\chapter{Overview of the Project}
\label{intro:overview-of-the-project}\label{intro:welcome-to-siglib-s-documentation}\label{intro::doc}

\section{Introduction}
\label{intro:introduction}
SigLib stands for Signature Library and is a suite of tools to query,
manipulate and process remote sensing imagery (primarily Synthetic
Aperture Radar (SAR) imagery) and store the data in a geodatabse. It
uses open source libraries and can be run on Windows or Linux.

There are 4 main \emph{modes} that it can run in (or combinations of these)
\begin{enumerate}
\item {} 
A data \textbf{Discovery Mode} where remote sensing scenes are discovered
by ingesting a copy of the Canadian Ice Service archive (or other
geodatabase containing metadata, with tweaks), or by crawling through
a hard drive and extracting metadata from zipped SAR scenes, or by
querying a table in a local database that contains geospatial
metadata. Queries take a Region Of Interest or \textbf{ROI shapefile} with
a specific format as input to delineate the
spatial and temporal search boundaries. The required attribute fields
and formats for the ROI are elaborated upon in a section below.

\item {} 
An \textbf{Exploratory Mode} where remote sensing scenes are made ready
for viewing. This includes opening zip files, converting imagery
(including Single Look Complex), geographical projection, cropping,
masking, image stretching, renaming, and pyramid generation. The user
must supply the name of a single zip file that contains the SAR
imagery, a directory where a batch of zip files to be prepared
resides, or a query that selects a list of zip files to be processed.

\item {} 
A \textbf{Scientific Mode} where remote sensing scenes can be converted to
sigma, beta, or gamma nought. Image data (from each band) is then subsampled
by way of an \textbf{ROIshapefile} that references every image and specific polygon to be
analyzed. These polygons represent sampling regions that are known
(a priori) or are hand digitized from Exploratory mode
images. Data can be stored in a table in a geodatabase for further
processing.

\item {} 
A \textbf{Polarimetric Mode} where quad-pol scenes are converted to sigma0,
cropped to tracking beacon instances, have polarimetric matricies generated,
polarimetric filtering, and polarimetric decompositions generated.

\end{enumerate}

These modes are brought together to work in harmony by \textbf{SigLib.py}, the
recommended way to interact with the software. This program reads-in a
configuration file that provides all the parameters required to do
various jobs. However, this is only one way to go... Anyone can call the
modules identified above from a custom made python script to do what
they wish, using the SigLib API

In addition, there are different ways to process \emph{input} through
SigLib.py that can be changed for these modes. You can input based on a
recursive \textbf{scan} of a directory for files that match a pattern; you
can input one \textbf{file} at a time (useful for parallelization, when many
processes are spawned by gnu parallel) and; you can input an SQL
\textbf{query} and run the resulting matching files through SigLib (note that
query input is not yet enabled, but it wouldn't take long).


\section{Acknowledgements}
\label{intro:acknowledgements}
This software was conceived and advanced initially by Derek Mueller
(while he was a Visiting Fellow at the Canadian Ice Service). Some code
was derived from from Defence Research and Development Canada (DRDC). At
CIS he benefited from discussions with Ron Saper, Angela Cheng and his salary
was provided via a CSA GRIP project (PI Roger De Abreu).

At Carleton this code was modified further and others have worked to
improve it since the early days at CIS: Cindy Lopes (workstudy student \&
computer programmer) 2012, Sougal Bouh-Ali (workstudy student \& computer
programmer) 2013-2016, and Cameron Fitzpatrick (computer programmer) 2018-Present.
Ron Saper, Anna Crawford and Greg Lewis-Paley helped out as well (indirectly).


\chapter{Overview of SigLib.py and its Dependencies}
\label{project::doc}\label{project:overview-of-siglib-py-and-its-dependencies}

\section{Dependencies}
\label{project:dependencies}
You will need a computer running Linux or Windows
\begin{itemize}
\item {} 
Python 2 (not 3), along with several scientific libraries - numpy,
pandas, psycopg2, matplotlib, datetime... It's recommended you install the
\emph{Anaconda Python Distribution} as it contains pretty well everything required.
www.anaconda.com

\item {} 
gdal/ogr libraries
www.osgeo.org

\item {} 
snap (sentinel-1 toolbox): \href{https://step.esa.int/main/download/snap-download/}{https://step.esa.int/main/download/snap-download/}
Make sure when downloading to configure python api for snapPy!

\item {} 
PostrgreSQL/PostGIS (could be on another computer)
www.postgresql.org / postgis.net

\item {} 
It is highly recommended that you have access to QGIS or ArcGIS Pro to
manipulate shapefiles

\end{itemize}


\section{Modules}
\label{project:modules}
There are several modules that are organized according to core
functionality.
\begin{enumerate}
\item {} 
\textbf{Util.py} - Several utilities for manipulating files,
shapefiles, etc

\item {} 
\textbf{Metadata.py} - used to discover and extract metadata from image
files

\item {} 
\textbf{Database.py} - used to interface between the PostGIS database for
storage and retrieval of information

\item {} 
\textbf{Image.py} - used to manipulate images, project, calibrate, crop,
etc.

\item {} 
\textbf{LogConcat.py} - used to combine individual log files into one
master .txt file, and separate log files containing errors for
analysis (Mainly for use after large runs in parallel)

\end{enumerate}

\textbf{SigLib.py} is the front-end of the software. It calls the modules
listed above and is, in turn controlled by a configuration file. To run,
simply edit the *.cfg file with the paths and inputs you want and then
run SigLib.py.

However, you can also code your own script to access the functionality
of the modules if you wish.


\section{Config File}
\label{project:config-file}
The \textbf{*.cfg} file is how you interface with SigLib. It needs to be
edited properly so that the job you want done will happen! Leave entry
blank if you are not sure. There are several categories of parameters:

\emph{Directories}
\begin{itemize}
\item {} 
scanDir = path to where you want SigLib to look for SAR image zip
files to work with

\item {} 
tmpDir = a working directory to extract zip files to
(A folder for temporary files that will only be used during the
running of the code, then deleted)

\item {} 
projDir = where projection definition files are found in well-known
text format (wkt)

\item {} 
vectDir = where vector layers are found (ROI shapefiles or masking
layers)

\item {} 
imgDir = a working directory for storing image processing
intermediate files and final output files

\item {} 
logDir = where logs are created

\item {} 
archDir = where CIS archive data are found

\item {} 
errorDir = where logConcat will send .log files with errors (for
proper review of bad zips at end of run)

\end{itemize}

\emph{Database}
\begin{itemize}
\item {} 
db = the name of the database you want to connect to

\item {} 
host = database hostname

\item {} 
create\_tblmetadata = 0 for append, = 1 for overwrite/create
a metadata table.

\item {} 
uploadROI = if the ROI file needs to be uploaded to the database. 0 if no, 1 if yes

\item {} 
table = name of table in database that Database.py will query
against to find imagery

\end{itemize}

\emph{Input}

\textbf{Note that path, query, and file are mutually exclusive options - sum of `Input'
options must = 1}
\begin{itemize}
\item {} 
path = 1 to scan a certain path and operate on all files within; 0
otherwise

\item {} 
query = 1 to scan over the results of a query and operate on all
files returned; 0 otherwise

\item {} 
file = 1 to run process on a certain file, which is passed as a
command line argument (\emph{note} this must be enabled to parallelize SigLib); 0
otherwise

\item {} 
scanFor = a file pattern to search for (eg. *.zip) - use when path=1

\item {} 
sql = define a custom query here for selecting data to process - use
when query=1. eg. SELECT location FROM tblmetadata WHERE granule =
`B0558007.img'

\end{itemize}

\emph{Process}
\begin{itemize}
\item {} 
data2db = 1 when you want to upload metadata to the metadata table in
the database

\item {} 
data2img = 1 when you want to manipulate images (as per specs below)

\item {} 
scientific = 1 when image manipulation requires Database.py

\item {} 
polarimetric = 1 when you want to do SAR polarimetry

\end{itemize}

\emph{MISC}
\begin{itemize}
\item {} 
proj = basename of wkt projection file (eg. lcc) in the projDir

\item {} 
imgtypes = types of images to process (Amplitude Image - amp, Sigma
Nought Image - sigma, Gamma Nought Image - gamma, Beta Nought
Image - beta)

\item {} 
imgformat = file format for output imagery (gdal convention)

\item {} 
roi = ROI Shapefile for Discovery or Scientific modes, stored in vectDir

\item {} 
roiproj = projection of the roi

\item {} 
crop = leave blank for no cropping, or four space-delimited numbers,
upper-left and lower-right corners (in proj above) that denote a crop
area: ul\_x ul\_y lr\_x lr\_y

\item {} 
maskshp = a polygon shapefile (with only one feature) to mask image data with

\item {} 
spatialrel = ST\_Contains (Search for images that fully contain the
roi polygon) or ST\_Intersects (Search for images that merely
intersect with the roi)

\end{itemize}


\section{Using a Config in an IDE}
\label{project:using-a-config-in-an-ide}
You can run SigLib inside an integrated development environment (Spyder,
IDLE, etc) or at the command line. In either case you must specify the
configuration file you wish to use:

\code{python /path\_to\_script/SigLib.py/ path\_to\_file/config\_file.cfg}


\section{Dimgname Convention}
\label{project:dimgname-convention}
“The nice thing about standards is that there are so many to chose from”
(A. Tannenbaum), but this gets annoying when you pull data from MDA,
CSA, CIS, PDC, ASF and they all use different file naming conventions.
So Derek made this problem worse with his own `standard image naming
convention' called \textbf{dimgname}. All files
processed by SigLib get named as follows, which is good for:
\begin{itemize}
\item {} 
sorting on date (that is the most important characteristic of an
image besides where the image is - and good luck conveying that
simply in a file name).

\item {} 
viewing in a list (because date is first, underscores keep the names
tidy in a list - you can look down to see the different beams,
satellites, etc.)

\item {} 
extensibility - you can add on to the file name as needed - add a
subscene or whatever on the end, it will sort and view the same as
before.

\item {} 
extracting metadata from the name (in a program or spreadsheet just
parse on ``\_'')

\end{itemize}

Template: date\_time\_sat\_beam\_data\_proj.ext

Example: 20080630\_225541\_r1\_scwa\_\_hh\_s\_lcc.tif

Table: \textbf{dimgname fields}

\begin{tabulary}{\linewidth}{|L|L|L|L|}
\hline
\textsf{\relax 
Position
} & \textsf{\relax 
Meaning
} & \textsf{\relax 
Example
} & \textsf{\relax 
Chars
}\\
\hline
Date
 & 
year month day
 & 
20080630
 & 
8
\\
\hline
Time
 & 
hour min sec
 & 
225541
 & 
6
\\
\hline
Sat
 & 
satellite/platform/sensor
 & 
r1,r2,e1,en
 & 
2
\\
\hline
Beam
 & 
beam for SAR, band combo for optical
 & 
st1\_\_,scwa\_,fqw20\_,134\_\_
 & 
5
\\
\hline
Band
 & 
pol for SAR, meaning of beam for optical (tc = true colour)
 & 
hh, hx, vx, vv, hv, qp
 & 
2
\\
\hline
Data
 & 
what is represented (implies a datatype to some extent)
 & 
a= amplitude, s=sigma, t=incidence,n=NESZ, o=optical
 & 
1
\\
\hline
Proj
 & 
projection
 & 
nil, utm, lcc, aea
 & 
3
\\
\hline
Ext
 & 
file extension
 & 
tif, rrd, aux, img
 & 
3
\\
\hline\end{tabulary}



\section{ROI.shp format}
\label{project:roi-shp-format}
The ROI.shp or Region Of Interest shapefile is what you need to extract
data. Basically it denotes \emph{where} and \emph{when} you want information. It
has to have certain fields to work properly. There are two basic
formats, based on whether you are using the \textbf{Discovery} or
\textbf{Scientific} mode. If you are interested in 1) finding out what
scenes/images might be available to cover an area or 2) generating
images over a given area then use the \emph{Discovery} format. If you have
examined the images already and have digitized polygons of areas that
you want to analyze (find statistics), then make sure those polygons are
stored in a shapefile using the \emph{Scientific} format. In either case you
must have the fields that are required for \emph{Both} formats in the table
below. You can add whatever other fields you wish and some suggestions
are listed below as \emph{Optional}.

The two fields which are required for both Discovery or Scientific mode
use may be confusing, so here are some further details with examples.
\begin{itemize}
\item {} 
OBJ - this is a unique identifier for a given area or object
(polygon) that you are interested in getting data for.

\item {} 
INSTID - A way to track OBJ that is repeatedly observed over time
(moving ice island, a lake during fall every year for 5 years). {[}If
it doesn't repeat just put `0'{]}

\end{itemize}


\section{A Note on Projections:}
\label{project:a-note-on-projections}
SigLib uses projections in two ways; either as .wkt files during image processing outside the database, or SRID values when using PostgreSQL/PostGIS. For when Database.py is not being used, projections should be downloaded as .wkt files from spatialreference.org and placed into a projection directory. If using Database.py functionality, make sure the spatial\_ref\_sys table is defined in your database. This table has a core of over 3000 spatial reference systems ready to use, but custom projections can be added very easily!

To add a custom spatial reference, download the desired projection in ``PostGIS spatial\_ref\_sys INSERT statement'' format from spatialreference.org. This option is an sql executable that can be run within PostgreSQL to add the desired projection into the spatial\_ref\_sys table.


\section{Example workflow:}
\label{project:example-workflow}
You could be interested in lake freeze-up in the Yukon, drifting ice
islands, or soil moisture in southern Ontario farm fields. First you
will want to find out what data are available, retrieve zip files and
generate imagery to look at. In this case use the \emph{Discovery} format.
Each lake, region that ice islands drift through or agricultural area
that you want to study would be given a unique OBJ. If you have only one
time period in mind for each, then INSTID would be `0' in all cases. If
however, you want to look at each lake during several autumns, ice
islands as they drift or farm fields after rain events, then each OBJ
will have several rows in your shapefile with a different FROMDATE and
TODATE. Then for each new row with the same OBJ, you must modify the
INSTID such that a string that is composed of OBJ+INSTID is unique
across your shapefile. This is what is done internally by SigLib and a
new field is generated called INST (in the PostGIS database). Note that
the FROMDATE and TODATE will typically be different for each OBJ+INSTID
combination.

If you know what imagery is available already, or if you have digitized
specific areas corresponding where you want to quantify backscatter (or
image noise, incidence angle, etc), then you should use the \emph{Scientific}
format. In this case, the principles are the same as in the \emph{Discovery}
mode but your concept of what an OBJ might be, will be different.
Depending on the study goals, you may want backscatter from the entire
lake, in which case your OBJ would be the same as in \emph{Discovery} mode,
however, the INSTID must be modified such that there is a unique
OBJ+INSTID for each image (or image acquisition time) you want to
retrieve data for. The scientific OBJ should change when you are hand
digitizing a specific subsample from each OBJ from the \emph{Discovery} mode.
For example:
\begin{itemize}
\item {} 
within each agricultural area you may want to digitize particular
fields;

\item {} 
instead of vast areas to look for ice islands you have actually
digitized each one at a precise location and time

\end{itemize}

Build your \emph{Scientific} ROI shapefile with the field IMGREF for each
unique OBJ+INSTID instead of the FROMDATE and TODATE. By placing the
dimgname of each image you want to look at in the IMGREF field, SigLib
can pull out the date and time and populate the DATEFROM and DATETO
fields automatically. Hint: the INSTID could be IMGREF if you wished
(since there is no way an OBJ would be in the same image twice).

Once you complete your ROI.shp you can name it whatever you like (just
don't put spaces in the filename, since that causes problems).

Table: \textbf{ROI.shp fields}

\begin{tabulary}{\linewidth}{|L|L|L|L|L|}
\hline
\textsf{\relax 
Field
} & \textsf{\relax 
Var. Type
} & \textsf{\relax 
Description
} & \textsf{\relax 
Example
} & \textsf{\relax 
ROI Format
}\\
\hline
OBJ
 & 
String
 & 
A unique identifier for each polygon object you are interested in
 & 
00001, 00002
 & 
Both
\\
\hline
INSTID
 & 
String
 & 
An iterator for each new row of the same OBJ
 & 
0,1,2,3,4
 & 
Both
\\
\hline
FROMDATE
 & 
String
 & 
ISO Date-time denoting the start of the time period of interest
 & 
2002-04-15 00:00:00
 & 
Discovery
\\
\hline
TODATE
 & 
String
 & 
ISO Date-time denoting the end of the time period of interest
 & 
2002-09-15 23:59:59
 & 
Discovery
\\
\hline
IMGREF
 & 
String
 & 
dimgname of a specific image known to contain the OBJ polygon (Spaces are underscores)
 & 
20020715 135903 r1 scwa  hh s lcc.tif
 & 
Scientific
\\
\hline
Name
 & 
String
 & 
A name for the OBJ is nice to have
 & 
Ward Hunt, Milne, Ayles
 & 
Optional
\\
\hline
Area
 & 
Float
 & 
You can calculate the Area of each polygon and put it here (choose whatever units you want)
 & 
23.42452
 & 
Optional
\\
\hline\end{tabulary}


\begin{DUlineblock}{0em}
\item[] Area       \textbar{} Float      \textbar{} You can calculate the Area of each polygon and put it here (choose whatever units you want)           \textbar{} 23.42452                                       \textbar{} Optional     \textbar{}
\end{DUlineblock}
\begin{itemize}
\item {} 
See folder ROISamples for example ROIs - Discovery and Scientific
mode

\end{itemize}


\chapter{TODO}
\label{project:todo}
*\# Make sure there is process/output testing and error trapping at
every major step.

*\# Develop a test suite of imagery for the project - R2 and R1 images
that are in different beam modes, orbit directions, even bad images to
test SigLib. (imagery with no EULA so it can be shared)
\begin{itemize}
\item {} 
Continue documentation
\begin{enumerate}
\item {} 
overarching documentation important too

\item {} 
UML diagram for visual

\item {} 
example scripts/configs

\item {} 
example ROI.shp

\end{enumerate}

\item {} 
add local? {[}Not sure exactly what this is{]}

\item {} 
investigate compatibility with python 3

\end{itemize}


\section{SigLib.py}
\label{project:siglib-py}\begin{itemize}
\item {} 
Does scientific work?

\end{itemize}


\section{Metadata.py}
\label{project:metadata-py}\begin{itemize}
\item {} 
get look direction for RSAT2, test against RSAT1

\end{itemize}


\section{Image.py}
\label{project:image-py}\begin{itemize}
\item {} 
test image crop and mask - in both modes

\item {} 
Sigma0 testing (image vs snap vs ZAPro)

\item {} 
compare snap equivilancy to gdal, if so remove unnessesary gdal code (clean!)

\end{itemize}


\section{Util.py}
\label{project:util-py}\begin{itemize}
\item {} 
deltree needs work (or can it be removed?)

\end{itemize}


\chapter{Using SigLib}
\label{tutorial::doc}\label{tutorial:using-siglib}
Welcome to the tutorial sections of the SigLib documentation! This section
gives a brief overview of how to use the Metadata,
Util, Database, and Image functions via SigLib and its config file,
or in a custom way via qryDatabase.


\section{Basic SigLib Setup}
\label{tutorial:basic-siglib-setup}
Before SigLib and its dependencies can be used for the first time, some
basic setup must first be completed. In the downloaded SigLib file, there
are five Python files (\emph{.py), a config file (}.cfg), and an extras folder
containing some odds and ends (including this very document you are reading!).

A number of folders must be created and refered to the
config file. Please see the config section of the documentation above for
the required folders. These directories are used to keep the various input,
temporary, and output files organized. Once created, the full path to each file
must be added to the config file alongside the directory it is set to represent.
The config file contains example path listings.

For SigLib.py to recognise and use the config file properly, your
Python IDE must be set up for running via the command line. The following
instructions are given for the Spyder Python IDE; the setup for other IDEs may vary.

1.Go to Run -\textgreater{} Configuration per file... (Ctrl + F6)
2.Under General Settings, check the box labeled \emph{Command Line Options:}
3.In the box to the right, put the full path to the config
file, including the config file itself and its extension.
4.Press the OK button to save the setting and close the
window


\section{Example \#1: Basic Radarsat2 Image Calibration using SigLib}
\label{tutorial:example-1-basic-radarsat2-image-calibration-using-siglib}
In this example we will be using SigLib to produce Tiff
images from Amplitude Radarsat2 image files.
Before any work beings in Python, the config file must be configured for this
type of job, see the figure below for the required settings.
Place a few Radarsat2 zip files in your scanDir, then open your IDE configured for
command line running, and run SigLib.

What will happen is as follows: The zipfile will be extracted to the temp
directory via Util.py. The metadata will then be extracted and saved to the output
directory, via Metadata.py. Image.py will create an initial Tiff image via GDAL or SNAPPY,
and saved to the output directory. The image will then be reprojected
and stretched into a byte-scaled Tiff file.
All intermediate files will then be cleaned and Siglib will move onto the next zipfile,
until all the files in the scanDir are converted.
\begin{figure}[htbp]
\centering
\capstart

\scalebox{0.500000}{\includegraphics{{basicCFG}.png}}
\caption{A basic config file for this task}\end{figure}


\section{Example \#2: Discover Radarsat metadata and upload to a geodatabase}
\label{tutorial:example-2-discover-radarsat-metadata-and-upload-to-a-geodatabase}
This example will be the first introduction to Database.py and PGAdmin.
In this example we will be uploading the metadata of Radarsat scenes to a
geodatabase for later reference (and for use in later examples). This process
will be done using the parallel library on linux. See \href{https://www.gnu.org/software/parallel}{https://www.gnu.org/software/parallel}
for documentation and downloads for the parallel library. \textbf{NOTE:} This example only
works on \emph{linux} machines, how the results of this example can be replicated
on other machines will be explained afterwards.

This job will be done via the data2db process of SigLib, as seen in the
config. Also, since we are running this example in parallel, the input
must be \textbf{File} not \textbf{Path}.

In this case, we need the metadata table in our geodatabase to already exist. If this table has not been created yet, run SigLib with ``create\_tblmetadata'' equal to 1, with all modes under \textbf{Process} equal to 0 before continuing with the rest of this example.

A review of the settings needed for this particular example can be
seen in the figure below.
\begin{figure}[htbp]
\centering
\capstart

\scalebox{0.500000}{\includegraphics{{uploadMeta}.png}}
\caption{Config file settings for discovering and uploading metadata.}\end{figure}

To start the parallel job:
\begin{enumerate}
\item {} 
Open a terminal

\end{enumerate}

2. cd into the directory containing all your radarsat images (They can be in multiple
directories, just make sure they are below the one you cd into, or they will
not be found)
3. Type in the terminal:
\textbf{find . -name `*.zip' -type f \textbar{} parallel -j 16 --nice 15 --progress python /path/to/SigLib.py/ /path/to/config.cfg/}
Where -j is the number of cores to use, and --nice is how nice the process will be to
other processes (I.E. A lower --nice level gives this job a higher priority over
other processes). The first directory is the location of your verison of SigLib.py,
the second is the location of the associated config file.

\textbf{NOTE:} ALWAYS test parallel on a small batch before doing a major run, to make
sure everything is running correctly.

Once started, Parallel will begin to step though your selected
directory looking for .zip files. Once one is found, it will pass it to one of the
16 availible (or however many cores you set) openings of Siglib.py. SigLib will
unzip the file via Util.py, grab the metadata via Metadata.py, then connect to your
desired database, and upload this retrieved metadata to the relational table
\emph{tblmetadata} (which will have to be created by running createTblMetadata() in
Database.py before parallelizing) via Database.py. This will repeat until parallel has
fully stepped through your selected directory.

Most SigLib process can be parallelized, as long as the correct config parameters
are set, and the above steps on starting a parallel job are followed.

The same results for this example can be achieved for non-linux machines by
putting all the zip files containing metadata for upload into your scanDir,
and using the same settings as in the above figure, except in the \emph{Input} section,
\textbf{File} must be set to 0, and \textbf{Path} must be set to 1.


\section{Example \#3: Scientific Mode!}
\label{tutorial:example-3-scientific-mode}
In this example, we will dive into the depths of SigLibs' Scientific Mode!
Scientific Mode (as described in an earlier section of this documentation) is a way of
taking normal radarsat images and converting them to a new image type (sigma0, beta0, and gamma0) followed by cropping and masking them into small
pieces via a scientific ROI. The ROI should contain a series of polygons representing regions of interest for different scenes. For example, the polygons could be individual farmers fields, or individual icebergs. The ROI created must be uploaded to the geodatabase for querying by SigLib. To upload the ROI specified in the config, set `uploadROI' equal to 1, as seen below in the example config. \textbf{NOTE:} This config setting \textbf{MUST} be 0 if running in parallel, or else the ROI will constantly be overwritten. This case also requires a database with SAR image footprints, like the one made in the previous example!
\begin{figure}[htbp]
\centering
\capstart

\scalebox{0.500000}{\includegraphics{{scientific}.png}}
\caption{Config file settings for scientific mode. Note that we are uploading an ROI in this example. The first time scientific is run with a new ROI, this setting will be nessesary, otherwise it can be set equal             to 0}\end{figure}

Once begun, this mode takes a SAR image in the scanDir, and calibrates it to the selected image type. Once completed, database.py is used to query the ROI against the image footprint to find which polygons in the ROI are within the scene being processed. Each of these hits is then processed one at a time, beginning with a bounding-box crop around the instance, followed by a mask using the ROI polygon (both queried via Database.py). At this point, each instance is projected and turned into its own TIFF file for delivery, or the image data for the instances is uploaded to a database table made to store data from this run.


\section{Example \#4: Polarimetric Mode!}
\label{tutorial:example-4-polarimetric-mode}
In this final example, we will look at using SigLib's Polarimetric mode. Polarimetric mode
uses the SNAP python library SnapPy to perform SAR polarimetry for quad-pol scenes containing
tracking beacon instances. Three different polarimetric operations are conducted in this mode: Matrix Generation, Polarimetric Speckle Filtering (Using Refined Lee Filter), and Polarimetric Decomposition Generation. All the matricies and decompositions available in SnapPy that are designed for quad-pol imagery are stored in lists in \emph{polarimetric} in \textbf{SigLib.py}, these can be edited to contain only desired options. No terrain-correction/reprojections are done in this mode.

This example requires a database table containing tracking beacon instances and one containing quad-pol SAR image footprints. The nessesary columns for the tracking beacons are geom, latitude, longitude, beaconid, and time (in UTC). The geom and time columns will be comparied to similar columns in the SAR footprints table. The sql statement to compare these two tables will need to be edited to match your column names, see \emph{beaconIntersections} in \textbf{Image.py} to make appropriate edits.
\begin{figure}[htbp]
\centering
\capstart

\scalebox{0.500000}{\includegraphics{{polarimetry}.png}}
\caption{Config file settings for polarimetry mode}\end{figure}

Once started, this mode goes through the images in the scan directory, processing one image at a time. The program checks to make sure the images are quad-pol, and then queries the geodatabase to see if any beacon pings are contained in the image within a 91 minute buffered timeframe of the SAR data being collected. If there are beacons in the image, the ID's, latitudes, and longitudes of the beacons are collected. The scene is then calibrated to sigma0. At this point, image processing begins per beacon instance in this scene. First, both polarimetric matricies, C3 and T3, are applied (two separate files are created, one with each). Each of these files is then speckle-filtered with a Refined-Lee Filter. After, each decomposition type specified is generated upon each matrix type (again, separate file for each). For the Touzi and H-A-Alpha Decompositions, they are generated four times per matrix, each with a different set of bands. Max conditions will generate 28 GeoTiff files per beacon instance, if both matricies and all snap decompositions are utilized.


\section{Conclusion}
\label{tutorial:conclusion}
This is the conclusion to the \emph{Using SigLib} section of this documentation. For
additional help in using SigLib.py and its dependencies, please refer to the next section
of this documentation, \emph{SigLib API}. This section gives and overview, the parameters,
and the outputs, of each function in the main five modules.


\chapter{SigLib API}
\label{code:siglib-api}\label{code::doc}

\section{SigLib}
\label{code:module-SigLib}\label{code:siglib}\index{SigLib (module)}
\textbf{SigLib.py}

This script is thr margin that brings together all the SigLib modules with a config script to query, maniputlate and process remote sensing imagery

\textbf{Created on} Mon Oct  7 20:27:19 2013 \textbf{@author:} Sougal Bouh Ali
\textbf{Modified on} Wed May  23 11:37:40 2018 \textbf{@reason:} Sent instance of Metadata to data2img instead of calling Metadata again \textbf{@author:} Cameron Fitzpatrick

Common Parameters of this Module:

\emph{zipfile} : a valid zipfile name with full path and extension

\emph{zipname} : zipfile name without path or extension

\emph{fname} : image filename with extention but no path

\emph{imgname} : image filename without extention

\emph{granule} : unique name of an image in string format
\index{SigLib (class in SigLib)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib}\pysigline{\strong{class }\code{SigLib.}\bfcode{SigLib}}~\index{createLog() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.createLog}\pysiglinewithargsret{\bfcode{createLog}}{\emph{zipfile=None}}{}
Creates log file that will be used to report progress and errors
\textbf{Parameters}
\begin{quote}

\emph{zipfile}
\end{quote}

\end{fulllineitems}

\index{data2db() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.data2db}\pysiglinewithargsret{\bfcode{data2db}}{\emph{meta}, \emph{db}, \emph{zipfile}}{}
Adds the image file metadata to tblmetadata table in the specified database.
Will create/overwrite the table tblmetadata if prompted (be carefull)

\textbf{Parameters}
\begin{quote}

\emph{meta} :   A metadata instance from Metadata.py

\emph{db}   :   database connection
\end{quote}

\end{fulllineitems}

\index{data2img() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.data2img}\pysiglinewithargsret{\bfcode{data2img}}{\emph{fname}, \emph{imgname}, \emph{zipname}, \emph{sattype}, \emph{granule}, \emph{zipfile}, \emph{sar\_meta}, \emph{unzipdir}}{}
Opens an image file and converts it to the format given in the config file

\textbf{Parameters}
\begin{quote}

\emph{fname}

\emph{imgname}

\emph{zipname}

\emph{sattype}  : satelite platform

\emph{granule}

\emph{zipfile}

\emph{sar\_meta} : instance of the Metadata class

\emph{unzipdir} : directory zipfiles were unzipped into
\end{quote}

\end{fulllineitems}

\index{handler() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.handler}\pysiglinewithargsret{\bfcode{handler}}{\emph{signum}, \emph{frame}}{}
Handles exceptions - most notably time out errors

\end{fulllineitems}

\index{polarimetric() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.polarimetric}\pysiglinewithargsret{\bfcode{polarimetric}}{\emph{db}, \emph{fname}, \emph{imgname}, \emph{zipname}, \emph{sattype}, \emph{granule}, \emph{zipfile}, \emph{sar\_meta}, \emph{unzipdir}}{}
This function will take full FQ images and perform desired polarimetric matrix generation(s), speckle filtering, and decomposition(s). 
Combinations can be set in the config file. BE CAREFULL, if no combination is specified, then all possible combinations will be performed, 
so be prepared for a long run-time and large amounts of data!

\textbf{Parameters}
\begin{quote}

\emph{db} : an instance of the Database class

\emph{fname}

\emph{imgname}

\emph{zipname}

\emph{sattype} : Satellite platform

\emph{granule}

\emph{zipfile}

\emph{sar\_meta} : an instance of the Metadata class

\emph{unzipdir} : location zipfiles were unzipped into
\end{quote}

\end{fulllineitems}

\index{proc\_Dir() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.proc_Dir}\pysiglinewithargsret{\bfcode{proc\_Dir}}{\emph{path}, \emph{pattern}}{}
Locates satelite image raw data files (zipfiles) using a
\emph{pattern} in \emph{path} search method, and then calls createImg()
to process the data into image.

\textbf{Parameters}
\begin{quote}

\emph{path}    : directory tree to scan

\emph{pattern} : file pattern to discover
\end{quote}

\end{fulllineitems}

\index{proc\_File() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.proc_File}\pysiglinewithargsret{\bfcode{proc\_File}}{\emph{zipfile}}{}
Locates a single satellite image zip file and processes it according 
to the config file.  Note this cannot be nested in proc\_dir since the 
logging structure and other elements must parallelizable

\textbf{Parameters}
\begin{quote}

\emph{zipfile}
\end{quote}

\end{fulllineitems}

\index{retrieve() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.retrieve}\pysiglinewithargsret{\bfcode{retrieve}}{\emph{zipfile}}{}
Given a zip file name this function will: find out what satellite it is, unzip it, get instance of metadata, then 
dependant on the config, save metadata in a file and/or one of the following: Process to image or process to database.

\textbf{Parameters}
\begin{quote}

\emph{zipfile}
\end{quote}

\end{fulllineitems}

\index{scientific() (SigLib.SigLib method)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.SigLib.scientific}\pysiglinewithargsret{\bfcode{scientific}}{\emph{db}, \emph{fname}, \emph{imgname}, \emph{zipname}, \emph{sattype}, \emph{granule}, \emph{zipfile}, \emph{sar\_meta}, \emph{unzipdir}}{}~\begin{description}
\item[{Process images `Scientifically', based on an ROI in the database, and per zipfile:}] \leavevmode
-Qry to find what polygons in the ROI overlap this image
-Process one polygon at a time (Project, crop, and mask), saving each as its own img file OR uploading img data to database

\end{description}

\textbf{Parameters}
\begin{quote}

\emph{db}       : instance of the Database class

\emph{fname}

\emph{zipname}

\emph{sattype}  : satellite platform

\emph{granule}

\emph{zipfile}

\emph{sar\_meta} : instance of the Metadata class

\emph{unzipdir} : directory zipfile was unzipped into
\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{Metadata}
\label{code:metadata}\index{Metadata (class in SigLib)}

\begin{fulllineitems}
\phantomsection\label{code:SigLib.Metadata}\pysiglinewithargsret{\strong{class }\code{SigLib.}\bfcode{Metadata}}{\emph{granule}, \emph{imgname}, \emph{path}, \emph{zipfile}, \emph{sattype}, \emph{loghandler=None}}{}
This is the metadata class for each image RSAT2, RSAT1 (ASF and CDPF)
\begin{quote}

\textbf{Parameters}
\begin{quote}

\emph{granule} : unique name of an image in string format

\emph{imgname} : image filename without extention

\emph{path} : path to the image in string format

\emph{zipfile} : a valid zipfile name with full path and extension

\emph{sattype}    : type of data (String)

\emph{loghandler} : A valid pre-set loghandler (Optional)
\end{quote}

\textbf{Returns}
\begin{quote}

An instance of Metadata
\end{quote}
\end{quote}

\end{fulllineitems}

\phantomsection\label{code:module-Metadata}\index{Metadata (module)}
\textbf{Metadata.py}

\textbf{Created on} Jan 1, 2009 \textbf{@author:} Derek Mueller

This module creates an instance of class Meta and contains functions to
query raw data files for metadata which is standardized and packaged for
later use, output to file, upload to database, etc.
\begin{quote}

\emph{This source code to extract metadata from CEOS-format RADARSAT-1 
data was developed by Defence Research and Development Canada
{[}Used with permission{]}}
\end{quote}

\textbf{Modified on} Wed May  23 11:37:40 2018 \textbf{@reason:} Sent instance of Metadata to data2img instead of calling Metadata again \textbf{@author:} Cameron Fitzpatrick
\index{Metadata (class in Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata}\pysiglinewithargsret{\strong{class }\code{Metadata.}\bfcode{Metadata}}{\emph{granule}, \emph{imgname}, \emph{path}, \emph{zipfile}, \emph{sattype}, \emph{loghandler=None}}{}
This is the metadata class for each image RSAT2, RSAT1 (ASF and CDPF)
\begin{quote}

\textbf{Parameters}
\begin{quote}

\emph{granule} : unique name of an image in string format

\emph{imgname} : image filename without extention

\emph{path} : path to the image in string format

\emph{zipfile} : a valid zipfile name with full path and extension

\emph{sattype}    : type of data (String)

\emph{loghandler} : A valid pre-set loghandler (Optional)
\end{quote}

\textbf{Returns}
\begin{quote}

An instance of Metadata
\end{quote}
\end{quote}
\index{clean\_metaASF() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.clean_metaASF}\pysiglinewithargsret{\bfcode{clean\_metaASF}}{\emph{result}}{}
Takes meta data from origmeta and checks it for completeness, coerces data types
splits values, if required and puts it all into a standard format

NOT TESTED!!

\textbf{Parameters}
\begin{quote}

\emph{result} : Dictionary of metadata
\end{quote}

\end{fulllineitems}

\index{clean\_metaCDPF() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.clean_metaCDPF}\pysiglinewithargsret{\bfcode{clean\_metaCDPF}}{\emph{result}}{}
Takes meta data from origmeta and checks it for completeness, coerces data types
splits values, if required and puts it all into a standard format

\textbf{Parameters}
\begin{quote}

\emph{result} : A dictonary of metadata
\end{quote}

\end{fulllineitems}

\index{createMetaDict() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.createMetaDict}\pysiglinewithargsret{\bfcode{createMetaDict}}{}{}
Creates a dictionary of all the metadata fields for an image
which can be written to file or sent to database

\textbf{Returns}
\begin{quote}

\emph{metadict} : Dictionary containing all the metadata fields
\end{quote}

\end{fulllineitems}

\index{extractGCPs() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.extractGCPs}\pysiglinewithargsret{\bfcode{extractGCPs}}{\emph{interval}}{}
Extracts the lat/long and pixel col/row of ground control points in the image

\textbf{Parameters}
\begin{quote}

\emph{interval} : line spacing between extractions
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{gcps (tuple)} : GCP's returned in tuple format
\end{quote}

\end{fulllineitems}

\index{getASFMetaCorners() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.getASFMetaCorners}\pysiglinewithargsret{\bfcode{getASFMetaCorners}}{\emph{ASFName}}{}
Use ASF Mapready to generate the metadata

\textbf{Parameters}
\begin{quote}

\emph{ASFName} : Name with extention, of the ASF meta file
\end{quote}

\end{fulllineitems}

\index{getASFProductType() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.getASFProductType}\pysiglinewithargsret{\bfcode{getASFProductType}}{\emph{ASFName}}{}
Description needed!

\textbf{Parameters}
\begin{quote}

\emph{ASFName} : Name with extention, of the ASF meta file
\end{quote}

\end{fulllineitems}

\index{getCEOSmetafile() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.getCEOSmetafile}\pysiglinewithargsret{\bfcode{getCEOSmetafile}}{}{}
Get the filenames for metadata

\end{fulllineitems}

\index{getCornerPoints() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.getCornerPoints}\pysiglinewithargsret{\bfcode{getCornerPoints}}{}{}
Given a set of geopts, calculate the corner coords to the nearest 1/2
pixel. Assumes that the corners are among the GCPs (not randomly placed)

\end{fulllineitems}

\index{getDimgname() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.getDimgname}\pysiglinewithargsret{\bfcode{getDimgname}}{}{}~\begin{description}
\item[{Create a filename that conforms to the dimgname standard naming convention:}] \leavevmode
yyyymmdd\_HHmmss\_sat\_beam\_pol...

See \emph{Dimgname Convention} in SigLib Documentation for more information

\end{description}

\textbf{Returns}
\begin{quote}

\emph{dimgname} : Name for image file conforming to standards above
\end{quote}

\end{fulllineitems}

\index{getMoreGCPs() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.getMoreGCPs}\pysiglinewithargsret{\bfcode{getMoreGCPs}}{\emph{n\_gcps}}{}
If you have a CDPF RSat1 image, gdal only has 15 GCPs
Perhaps you want more?  If so, use this function.
It will grab all the GCPs available (3 on each line) and
subselect n\_gcps of these to return.

The GCPs will not necessarily be on the `bottom corners' since the gcps
will be spaced evenly to get n\_gcps (or more if not divisible by 3)
If you want corners the only way to guarantee this is to set n\_gcps = 6

\textbf{Parameters}
\begin{quote}

\emph{n\_gcps}      : \# of GCP's to return
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{gcps (tuple)} : GCP's specified returned in tuple format
\end{quote}

\end{fulllineitems}

\index{getRS2metadata() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.getRS2metadata}\pysiglinewithargsret{\bfcode{getRS2metadata}}{}{}
Open a Radarsat2 product.xml file and get all the required metadata

\end{fulllineitems}

\index{get\_ceos\_metadata() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.get_ceos_metadata}\pysiglinewithargsret{\bfcode{get\_ceos\_metadata}}{\emph{*file\_names}}{}
Take file names as input and return a dictionary of metadata
file\_names is a list of strings or a string (with one filename)

This source code to extract metadata from CEOS-format RADARSAT-1 
data was developed by Defence Research and Development Canada
{[}Used with Permission{]}

\textbf{Parameters}
\begin{quote}

\emph{file\_names} : List of strings
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{result}     : Dictionary of Metadata
\end{quote}

\end{fulllineitems}

\index{getgdalmeta() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.getgdalmeta}\pysiglinewithargsret{\bfcode{getgdalmeta}}{}{}
Open file with gdal and get metadata that it can read. Limited!

\textbf{Returns}
\begin{quote}

\emph{gdal\_meta} : Metadata found by gdal
\end{quote}

\end{fulllineitems}

\index{saveMetaFile() (Metadata.Metadata method)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.Metadata.saveMetaFile}\pysiglinewithargsret{\bfcode{saveMetaFile}}{\emph{dir='`}}{}
Makes a text file with the image metadata

\end{fulllineitems}


\end{fulllineitems}

\index{byte2int() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.byte2int}\pysiglinewithargsret{\code{Metadata.}\bfcode{byte2int}}{\emph{byte}}{}
Reads a byte and converts to an integer

\end{fulllineitems}

\index{date2doy() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.date2doy}\pysiglinewithargsret{\code{Metadata.}\bfcode{date2doy}}{\emph{date}, \emph{string=False}, \emph{float=False}}{}
Provide a python datetime object and get an integer or string (if string=True) doy, fractional DayOfYear(doy) returned if float=True

\textbf{Parameters}
\begin{quote}

\emph{date} : Date in python datetime convension
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{doy}  : Day of year
\end{quote}

\end{fulllineitems}

\index{datetime2iso() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.datetime2iso}\pysiglinewithargsret{\code{Metadata.}\bfcode{datetime2iso}}{\emph{datetimeobj}}{}
Return iso string from a python datetime

\end{fulllineitems}

\index{getEarthRadius() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.getEarthRadius}\pysiglinewithargsret{\code{Metadata.}\bfcode{getEarthRadius}}{\emph{ellip\_maj}, \emph{ellip\_min}, \emph{plat\_lat}}{}
Calculates the earth radius at the latitude of the satellite from the ellipsoid params

\end{fulllineitems}

\index{getGroundRange() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.getGroundRange}\pysiglinewithargsret{\code{Metadata.}\bfcode{getGroundRange}}{\emph{slantRange}, \emph{radius}, \emph{sat\_alt}}{}
Finds the ground range from nadir which corresponds to a given slant range
must be an slc image, must have calculated the slantRange first

\end{fulllineitems}

\index{getSlantRange() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.getSlantRange}\pysiglinewithargsret{\code{Metadata.}\bfcode{getSlantRange}}{\emph{gsr}, \emph{pixelSpacing}, \emph{n\_cols}, \emph{order\_Rg}, \emph{groundRangeOrigin=0.0}}{}~\begin{description}
\item[{gsr = ground to slant range coefficients -a list of 6 floats}] \leavevmode
pixelSpacing - the image resolution, n\_cols - how many pixels in range
ground range orig - for RSat2 (seems to be zero always)

Valid for SLC as well as SGF

\end{description}

\end{fulllineitems}

\index{getThetaPixel() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.getThetaPixel}\pysiglinewithargsret{\code{Metadata.}\bfcode{getThetaPixel}}{\emph{RS}, \emph{r}, \emph{h}}{}
Calc the incidence angle at a given pixel, angle returned in radians

\end{fulllineitems}

\index{getThetaVector() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.getThetaVector}\pysiglinewithargsret{\code{Metadata.}\bfcode{getThetaVector}}{\emph{n\_cols}, \emph{slantRange}, \emph{radius}, \emph{sat\_alt}}{}
Make a vector of incidence angles in range direction

\end{fulllineitems}

\index{get\_data\_block() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.get_data_block}\pysiglinewithargsret{\code{Metadata.}\bfcode{get\_data\_block}}{\emph{fp}, \emph{offset}, \emph{length}}{}
Gets a block of data from file

\textbf{Parameters}
\begin{quote}

\emph{fp} : Open file to read data block from

\emph{offset} : How far down the file to begin the block

\emph{length} : Length of the data block
\end{quote}

\end{fulllineitems}

\index{get\_field\_value() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.get_field_value}\pysiglinewithargsret{\code{Metadata.}\bfcode{get\_field\_value}}{\emph{data}, \emph{field\_type}, \emph{length}, \emph{offset}}{}
Take a line of data and convert it to the appropriate data type

\textbf{Parameters}
\begin{quote}

\emph{data}       :  Line of data read from the file

\emph{field\_type} :  Datatype line is (ASCII, Integer, Float, Binary)

\emph{length}     :  Length of line

\emph{offset}     :  How far down the block the line is
\end{quote}

\textbf{Returns}
\begin{quote}

converted data\_str
\end{quote}

\end{fulllineitems}

\index{readdate() (in module Metadata)}

\begin{fulllineitems}
\phantomsection\label{code:Metadata.readdate}\pysiglinewithargsret{\code{Metadata.}\bfcode{readdate}}{\emph{date}, \emph{sattype}}{}
Takes a Rsat2 formated date 2009-05-31T14:43:17.184550Z
and converts it to python datetime. Sattype needed due to
differing date convensions between RS2 and CDPF.

\textbf{Parameters}
\begin{quote}

\emph{date} : Date in Rsat2 format

\emph{sattype} : Satellite type (RS2, CDPF)
\end{quote}

\textbf{Returns}
\begin{quote}

Date in python datetime convension
\end{quote}

\end{fulllineitems}



\section{Image}
\label{code:module-Image}\label{code:image}\index{Image (module)}
\textbf{imgProcess.py}

\textbf{Created on} 14 Jul  9:22:16 2009 \textbf{@author:} Derek Mueller

This module creates an instance of class Image. It creates an image to 
contain Remote Sensing Data as an amplitude, sigma naught, noise or theta
(incidence angle) image, etc. This image can be subsequently projected,
cropped, masked, stretched, etc.

\textbf{Modified on} 3 Feb  1:52:10 2012 \textbf{@reason:} Repackaged for r2convert \textbf{@author:} Derek Mueller
\textbf{Modified on} 23 May 14:43:40 2018 \textbf{@reason:} Added logging functionality \textbf{@author:} Cameron Fitzpatrick
\textbf{Modified on} 9 Aug  11:53:42 2019 \textbf{@reason:} Added in/replaced functions in this module with snapPy equivilants \textbf{@author:} Cameron Fitzpatrick

\textbf{Common Parameters of this Module:}

\emph{zipfile} : a valid zipfile name with full path and extension

\emph{zipname} : zipfile name without path or extension

\emph{fname} : image filename with extention but no path

\emph{imgname} : image filename without extention

\emph{granule} : unique name of an image in string format

\emph{path} : path to the image in string format
\index{Image (class in Image)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image}\pysiglinewithargsret{\strong{class }\code{Image.}\bfcode{Image}}{\emph{fname}, \emph{path}, \emph{meta}, \emph{imgType}, \emph{imgFormat}, \emph{zipname}, \emph{imgDir}, \emph{tmpDir}, \emph{loghandler=None}, \emph{pol=False}}{}
This is the Img class for each image.  RSAT2, RSAT1 (CDPF)

Opens the file specified by fname, passes reference to the metadata class and declares the imgType of interest.
\begin{quote}

\textbf{Parameters}
\begin{quote}

\emph{fname}

\emph{path}

\emph{meta}      : reference to the meta class

\emph{imgType}   : amp, sigma, beta or gamma

\emph{imgFormat} : gdal format code gtiff, vrt

\emph{zipname}
\end{quote}
\end{quote}
\index{applyStretch() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.applyStretch}\pysiglinewithargsret{\bfcode{applyStretch}}{\emph{stats}, \emph{procedure='std'}, \emph{sd=3}, \emph{bitDepth=8}, \emph{sep=False}}{}
Given an array of stats per band, will stretch a multiband image to the dataType based on
procedure (either std for standard deviation, with +ve int in keyword sd,
or min-max, also a linear stretch).

\emph{A nodata value of 0 is used in all cases}

\emph{For now, dataType is byte and that's it}

\textbf{Note:} gdal\_translate -scale does not honour nodata values
See: \href{http://trac.osgeo.org/gdal/ticket/3085}{http://trac.osgeo.org/gdal/ticket/3085}

Have to run this one under the imgWrite code. The raster bands must be integer, float or byte
and int data assumed to be only positive. Won't work very well for dB scaled data (obviously)
it is important that noData is set to 0 and is meaningful.

sep =  separate: applies individual stretches to each band (=better visualization/contrast)

!sep = together: applies the same stretch to all bands (looks for the band with the greatest dynamic range) (=more `correct')

For further ideas see: \href{http://en.wikipedia.org/wiki/Histogram\_equalization}{http://en.wikipedia.org/wiki/Histogram\_equalization}

\textbf{Parameters}
\begin{quote}

\emph{stats} : Array of stats for a band, in arrary: band, range, dtype, nodata, min,max,mean,std

\emph{procedure} : std or min-max

\emph{sd} : \# of standard deviations

\emph{bitDepth} : \# of bits per pixel

\emph{sep} : False for same stretch to all bands, True for individual stretches
\end{quote}

\end{fulllineitems}

\index{cleanFiles() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.cleanFiles}\pysiglinewithargsret{\bfcode{cleanFiles}}{\emph{levels={[}'crop'{]}}}{}
Removes intermediate files that have been written within the workflow.

Input a list of items to delete: raw, nil, proj, crop

\textbf{Parameters}
\begin{quote}

\emph{levels} : a list of different types of files to delete
\end{quote}

\end{fulllineitems}

\index{compress() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.compress}\pysiglinewithargsret{\bfcode{compress}}{}{}
Use gdal to LZW compress an image

\end{fulllineitems}

\index{cropBig() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.cropBig}\pysiglinewithargsret{\bfcode{cropBig}}{\emph{llur}, \emph{subscene}}{}
If cropping cannot be done in a straight-forward way (cropSmall), gdalwarp is used instead

\textbf{Parameters}
\begin{quote}

\emph{llur}     : list/tuple of tuples in projected units

\emph{subscene} : the name of a subscene
\end{quote}

\end{fulllineitems}

\index{cropImg() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.cropImg}\pysiglinewithargsret{\bfcode{cropImg}}{\emph{ullr}, \emph{subscene}}{}
Given the cropping coordinates, this function tries to crop in a straight-forward way using cropSmall.
If this cannot be accomplished then cropBig will do the job.

\textbf{Parameters}
\begin{quote}

\emph{ullr}     : upper left and lower right coordinates

\emph{subscene} : the name of a subscene
\end{quote}

\end{fulllineitems}

\index{cropSmall() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.cropSmall}\pysiglinewithargsret{\bfcode{cropSmall}}{\emph{urll}, \emph{subscene}}{}
This is a better way to crop because there is no potential for warping.
However, this will only work if the region falls completely within the image.

\textbf{Parameters}
\begin{quote}

\emph{urll}     : list/tuple of tuples in projected units

\emph{subscene} : the name of a subscene
\end{quote}

\end{fulllineitems}

\index{decomp() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.decomp}\pysiglinewithargsret{\bfcode{decomp}}{\emph{format='imgFormat'}}{}
Takes an input ds of a fully polarimetric image and writes an image of
the data using a pauli decomposition.

Differs from imgWrite because it ingests all bands at once...

\end{fulllineitems}

\index{decomposition\_generation() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.decomposition_generation}\pysiglinewithargsret{\bfcode{decomposition\_generation}}{\emph{decomposition}, \emph{matrix=None}, \emph{input=None}, \emph{dir=None}, \emph{beaconid=None}, \emph{outputType=0}, \emph{amp=False}}{}
Generate chosen decomposition on a fully polarimetric product, if looking to create an amplitude image with quad-pol data, set amp to True
and send either a Pauli Decomposition or Sinclair Decomposition

\textbf{Parameters}
\begin{quote}

\emph{decomposition} : decomposition to be generated. options include: Sinclair Decomposition, Pauli Decomposition, Freeman-Durden Decomposition, Yamagushi Decomposition, van Zyl Decomposition, H-A-Alpha Quad Pol Decomposition, Cloude Decomposition, or Touzi Decomposition

\emph{input} : filename with path of snap raster (.dim) to have decomposition generated upon (must be calibrated and have a matrix generated)

\emph{matrix} : The matrix (string) that was generated on this product

\emph{dir} : directory that finished tifs will be stored in

\emph{outputType} : option to select which set of output parameters that will be used for the Touzi or HAAlpha (1-8, leave 0 for none)

\emph{amp} : True if looking to generate Pauli or Sinclair decomposition to create quad-pol amp image
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{output} : filename of new product
\end{quote}

\end{fulllineitems}

\index{fnameGenerate() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.fnameGenerate}\pysiglinewithargsret{\bfcode{fnameGenerate}}{\emph{projout=None}, \emph{subset=None}, \emph{band=None}, \emph{cal=False}, \emph{TC=False}, \emph{DC=False}}{}
Generate a specific filename for this product.

\textbf{Returns}
\begin{quote}

\emph{bands}    : Integer

\emph{dataType} : Gdal data type

\emph{outname}  : New filename
\end{quote}

\end{fulllineitems}

\index{getAmp() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.getAmp}\pysiglinewithargsret{\bfcode{getAmp}}{\emph{datachunk}}{}
return the amplitude, given the amplitude... but make room for
the nodata value by clipping the highest value...

\textbf{Parameters}
\begin{quote}

\emph{datachunk} : Chunk of data being processed
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{outdata} : chunk data in amplitude format
\end{quote}

\end{fulllineitems}

\index{getBandData() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.getBandData}\pysiglinewithargsret{\bfcode{getBandData}}{\emph{band}}{}
opens an img file and reads in data from a given band
assume that the dataset is small enough to fit into memory all at once

\textbf{Parameters}
\begin{quote}

\emph{Band} : Array of data for a specific band
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{imgData}  : data from the given band

\emph{xSpacing} : size of pixel in x direction (decimal degrees)

\emph{ySpacing} : size of pixel in y direction (decimal degrees)
\end{quote}

\end{fulllineitems}

\index{getImgStats() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.getImgStats}\pysiglinewithargsret{\bfcode{getImgStats}}{}{}
Opens a raster and calculates (approx) the stats
returns an array - 1 row per band
cols: band, dynamicRange, dataType, nodata value, min, max, mean, std

\textbf{Returns}
\begin{quote}

\emph{stats} : stats from raster returned in an array of 1 row per band
\end{quote}

\end{fulllineitems}

\index{getMag() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.getMag}\pysiglinewithargsret{\bfcode{getMag}}{\emph{datachunk}}{}
return the magnitude of the complex number

\end{fulllineitems}

\index{getNoise() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.getNoise}\pysiglinewithargsret{\bfcode{getNoise}}{\emph{n\_lines}}{}
For making an image with the noise floor as data

\end{fulllineitems}

\index{getPhase() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.getPhase}\pysiglinewithargsret{\bfcode{getPhase}}{\emph{datachunk}}{}
Return the phase (in radians) of the data (must be complex/SLC)

\end{fulllineitems}

\index{getSigma() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.getSigma}\pysiglinewithargsret{\bfcode{getSigma}}{\emph{datachunk}, \emph{n\_lines}}{}
Calibrate data to Sigma Nought values (linear scale)

\textbf{Parameters}
\begin{quote}

\emph{datachunk} : chunk of data being processed

\emph{n\_lines} : size of the chunk
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{caldata} : calibrated chunk
\end{quote}

\end{fulllineitems}

\index{getTheta() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.getTheta}\pysiglinewithargsret{\bfcode{getTheta}}{\emph{n\_lines}}{}
For making an image with the incidence angle as data

\end{fulllineitems}

\index{imgWrite() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.imgWrite}\pysiglinewithargsret{\bfcode{imgWrite}}{\emph{format='imgFormat'}, \emph{stretchVals=None}}{}
Takes an input dataset and writes an image.

self.imgType could be 1) amp, 2) sigma, 3) noise, 4) theta

all bands are output (amp, sigma)

Also used to scale an integer img to byte with stretch, if stretchVals are included
\begin{description}
\item[{Note there is a parameter called chunk\_size hard coded here that could be changed }] \leavevmode
If you are running with lots of RAM

\end{description}

\end{fulllineitems}

\index{makeAmp() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.makeAmp}\pysiglinewithargsret{\bfcode{makeAmp}}{}{}
Use snap bandMaths to create amplitude band for SLC products

\end{fulllineitems}

\index{makePyramids() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.makePyramids}\pysiglinewithargsret{\bfcode{makePyramids}}{}{}
Make image pyramids for fast viewing at different scales (used in GIS)

\end{fulllineitems}

\index{maskImg() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.maskImg}\pysiglinewithargsret{\bfcode{maskImg}}{\emph{mask}, \emph{vectdir}, \emph{side}, \emph{imgType}}{}
Masks all bands with gdal\_rasterize using the `layer'

side = `inside' burns 0 inside the vector, `outside' burns outside the vector

Note: make sure that the vector shapefile is in the same proj as img (Use reprojSHP from ingestutil)

\textbf{Parameters}
\begin{quote}

\emph{mask}    : a shapefile used to mask the image(s) in question

\emph{vectdir} : directory where the mask shapefile is

\emph{side}    : `inside' or `outside' depending on desired mask result

\emph{imgType} : the image type
\end{quote}

\end{fulllineitems}

\index{matrix\_generation() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.matrix_generation}\pysiglinewithargsret{\bfcode{matrix\_generation}}{\emph{matrix}, \emph{input}}{}
Generate chosen matrix for calibrated quad-pol product

\textbf{Parameters}
\begin{quote}

\emph{matrix} : matrix to be generated. options include: C3, C4, T3, or T4

\emph{input} : filename with path of snap raster (.dim) to have matrix generated upon (must be calibrated)
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{output} : filename of new product
\end{quote}

\end{fulllineitems}

\index{openDataset() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.openDataset}\pysiglinewithargsret{\bfcode{openDataset}}{\emph{fname}, \emph{path='`}}{}
Opens a dataset with gdal

\textbf{Parameters}
\begin{quote}

\emph{fname} : filename
\end{quote}

\end{fulllineitems}

\index{polarFilter() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.polarFilter}\pysiglinewithargsret{\bfcode{polarFilter}}{\emph{input}}{}
Apply a speckle filter on a fully polarimetric product

\textbf{Parameters}
\begin{quote}

\emph{input} : filename with path of snap raster (.dim) to filter
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{output} : filename of new product
\end{quote}

\end{fulllineitems}

\index{projectImg() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.projectImg}\pysiglinewithargsret{\bfcode{projectImg}}{\emph{projout}, \emph{projdir}, \emph{format=None}, \emph{resample='bilinear'}, \emph{clobber=True}}{}
Looks for a file, already created and projects it to a vrt file.

\textbf{Parameters}
\begin{quote}

\emph{projout}  : projection base name

\emph{projdir}  : path to the projection

\emph{format}   : the image format, defaults to VRT

\emph{resample} : resample method (as per gdalwarp)

\emph{clobber}  : True/False should old output be overwritten?
\end{quote}

\textbf{Note} The pixel IS NOT prescribed (it will be the smallest possible)

\end{fulllineitems}

\index{reduceImg() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.reduceImg}\pysiglinewithargsret{\bfcode{reduceImg}}{\emph{xfactor}, \emph{yfactor}}{}
Uses gdal to reduce the image by a given factor in x and y(i.e, factor 2 is 50\%
smaller or half the \# of pixels). It overwrites the original.

\textbf{Parameters}
\begin{quote}

\emph{xfactor} : float

\emph{yfactor} : float
\end{quote}

\end{fulllineitems}

\index{snapCalibration() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.snapCalibration}\pysiglinewithargsret{\bfcode{snapCalibration}}{\emph{outDataType='sigma'}, \emph{saveInComplex=False}}{}
This fuction calibrates radarsat images into sigma, beta, or gamma

\textbf{Parameters}
\begin{quote}

\emph{outDataType} : Type of calibration to perform (sigma, beta, or gamma), default is sigma

\emph{saveInComplex} : Output complex sigma data (for polarimetric mode)
\end{quote}

\end{fulllineitems}

\index{snapDataTypeConv() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.snapDataTypeConv}\pysiglinewithargsret{\bfcode{snapDataTypeConv}}{\emph{outFormat='GeoTiff-BigTiff'}}{}
Convert image data to byte format using gdal

\textbf{Parameters}
\begin{quote}

\emph{outFormat} : Format of product this function returns, default is GeoTiff-BigTiff
\end{quote}

\end{fulllineitems}

\index{snapSubset() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.snapSubset}\pysiglinewithargsret{\bfcode{snapSubset}}{\emph{idNum}, \emph{lat}, \emph{longt}, \emph{ullr=None}}{}
Using lat long provided, create bounding box 200x200 pixels around it, and subset this
(This requires id, lat, and longt)
OR
Using ul and lr coordinates of bounding box, subset
(This requires id and ullr)

\textbf{parameters}
\begin{quote}

\emph{idNum} : id \# of subset region (for filenames, each subset region should have unique id)

\emph{lat} : latitiude of beacon at centre of subset (Optional)

\emph{longt} : longitude of beacon at centre of subset (Optional)

\emph{ullr} : Coordinates of ul and lr corners of bounding box to subset to (Optional)
\end{quote}

\end{fulllineitems}

\index{snapTC() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.snapTC}\pysiglinewithargsret{\bfcode{snapTC}}{\emph{proj}, \emph{projDir}, \emph{existingInput=True}, \emph{smooth=True}, \emph{outFormat='BEAM-DIMAP'}}{}
Perform an Ellipsoid-Correction using snap. This function also projects the product

\textbf{Parameters}
\begin{quote}

\emph{proj} : name of wkt projection file (minus file extension)

\emph{projDir} : directory containing projection file

\emph{existingInput} : If a snap-product has already been created before this function (default is True)

\emph{smooth} : If quanitative data, do not smooth (Smooth using Bilinear resampling for quality)

\emph{outFormat} : Format of product this function returns, default is BEAM-DIMAP
\end{quote}

\end{fulllineitems}

\index{stretchLinear() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.stretchLinear}\pysiglinewithargsret{\bfcode{stretchLinear}}{\emph{datachunk}, \emph{scaleRange}, \emph{dynRange}, \emph{minVal}, \emph{offset=0}}{}
Simple linear rescale: where min (max) can be the actual min/max or mean+/- n*std or any other cutoff

Note: make sure min/max don't exceed the natural limits of dataType
takes a numpy array datachunk the range to scale to, the range to scale
from, the minVal to start from and an offset required for some stretches
(see applyStretch keyword sep/tog)

\textbf{Parameters}
\begin{quote}

\emph{datachunk}   : array

\emph{scaleRange}  : Range to scale to

\emph{dynRange}    : Range to scale from

\emph{minVal}      : strating min value
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{stretchData} : datachunk, now linearly rescaled
\end{quote}

\end{fulllineitems}

\index{vrt2RealImg() (Image.Image method)}

\begin{fulllineitems}
\phantomsection\label{code:Image.Image.vrt2RealImg}\pysiglinewithargsret{\bfcode{vrt2RealImg}}{\emph{subset=None}}{}
Used to convert a vrt to a tiff (or another image format)

\end{fulllineitems}


\end{fulllineitems}



\section{Database}
\label{code:database}\phantomsection\label{code:module-Database}\index{Database (module)}
\textbf{Database.py}

\textbf{Created on} Tue Feb 12 23:12:13 2013 \textbf{@author:} Cindy Lopes

This module creates an instance of class Database and connects to a database to
create, update and query tables.

Tables of note include:

\textbf{table\_to\_query} - a table that contains metadata that is gleaned by a directory scan

\textbf{roi\_tbl} - a table with a region of interest (could be named something else)

\textbf{trel\_roiinst\_con} or \_int - a relational table that results from a spatial query

\textbf{tblArchive} - a copy of the metadata from the CIS image archive

\textbf{Modified on} 23 May 14:43:40 2018 \textbf{@reason:} Added logging functionality \textbf{@author:} Cameron Fitzpatrick
\index{Database (class in Database)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database}\pysiglinewithargsret{\strong{class }\code{Database.}\bfcode{Database}}{\emph{table\_to\_query}, \emph{dbname}, \emph{loghandler=None}, \emph{user=None}, \emph{password=None}, \emph{port=`5432'}, \emph{host='localhost'}}{}
This is the Database class for each database connection.
\begin{description}
\item[{Creates a connection to the specified database.  You can connect as a specific user or }] \leavevmode
default to your own username, which assumes you have privileges and a password stored in your  \textasciitilde{}/.pgpass file

Note: if you have any issues with a bad query, send a rollback to the database to reset the connection.
\textgreater{}\textgreater{}\textgreater{}\textgreater{}db.connection.rollback()

\textbf{Parameters}
\begin{quote}

\emph{dbname}   : database name

\emph{user}     : user with read or write (as required) access on the specified databse (eg. postgres user has read/write access to all databses)

\emph{password} : password to go with user

\emph{port}     : server port (i.e. 5432)

\emph{host}     : hostname of postgres server
\end{quote}

\end{description}
\index{beaconIntersections() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.beaconIntersections}\pysiglinewithargsret{\bfcode{beaconIntersections}}{\emph{beacontable}, \emph{granule}}{}
Get id, lat and long of beacons that intersect the image within a half hour of the image data being collected

\textbf{Parameters}
\begin{quote}

\emph{beacontable} : database table containing beacon tracks

\emph{granule} : unique identifier of image being analysed
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{rows} : all beacon pings that meet requirements. Each row has three columns: beacon id, lat, and long
\end{quote}

\end{fulllineitems}

\index{beaconShapefilesToTables() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.beaconShapefilesToTables}\pysiglinewithargsret{\bfcode{beaconShapefilesToTables}}{\emph{dirName}}{}
Takes a directory containing beacon shape files and converts them to tables and 
inserts them into the database appending \emph{beacon\_} before the name

\textbf{Parameters}
\begin{quote}

\emph{dirName} : Directory containing the beacon shapefiles
\end{quote}

\end{fulllineitems}

\index{convertGPSTime() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.convertGPSTime}\pysiglinewithargsret{\bfcode{convertGPSTime}}{\emph{shpTable}}{}
Takes a shape file and converts the gps\_time from character type to timestamp time.

\textbf{Parameters}
\begin{quote}

\emph{shpTable} : Shapefile table in the database
\end{quote}

\end{fulllineitems}

\index{createTblMetadata() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.createTblMetadata}\pysiglinewithargsret{\bfcode{createTblMetadata}}{}{}
Creates a metadata table of name specified in the cfg file under Table. It overwrites if that table name already exist, be careful!

\end{fulllineitems}

\index{exportToCSV() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.exportToCSV}\pysiglinewithargsret{\bfcode{exportToCSV}}{\emph{qryOutput}, \emph{outputName}}{}
Given a dictionary of results from the database and a filename puts all the results
into a csv with the filename outputName

\textbf{Parameters}
\begin{quote}

\emph{qryOutput}  : output from a query - needs to be a tupple - numpy data and list of column names

\emph{outputName} : the file name
\end{quote}

\end{fulllineitems}

\index{imgData2db() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.imgData2db}\pysiglinewithargsret{\bfcode{imgData2db}}{\emph{imgData}, \emph{xSpacing}, \emph{ySpacing}, \emph{bandName}, \emph{inst}, \emph{dimgname}, \emph{granule}}{}
Upload image data as an array to a new database table

What is needed by function: imgData, the imgType, the bandName, the inst, dimgname and granule        
What is computed to add to upload: count, mean, std, min, max for non-zero elements

\textbf{Parameters}
\begin{quote}

\emph{imgData}   : Pixel values

\emph{xSpacing}  :

\emph{ySpacing}  :

\emph{bandName}  : Name of the band being uploaded

\emph{inst}      : instance id

\emph{dimgname}  : Image name

\emph{granule}   : granule name
\end{quote}

\end{fulllineitems}

\index{meta2db() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.meta2db}\pysiglinewithargsret{\bfcode{meta2db}}{\emph{metaDict}, \emph{overwrite=False}}{}
Uploads image metadata to the database as discovered by the meta module.
\emph{meta} is a dictionary - no need to upload all the fields (some are not
included in the table structure)

Note that granule and dimgname are unique - as a precaution - a first query
deletes records that would otherwise be duplicated. 
This assumes that they should be overwritten!

\textbf{Parameters}
\begin{quote}

\emph{metaDict} : dictionnary containing the metadata
\end{quote}

\end{fulllineitems}

\index{nameRelationTable() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.nameRelationTable}\pysiglinewithargsret{\bfcode{nameRelationTable}}{\emph{roi}, \emph{spatialrel}}{}
Automatically gives a name to a relational table in the format: ``trel'' + roi + ``img'' + \_int or \_con (in reference to spatialrel)

\textbf{Parameters}
\begin{quote}

\emph{roi}        : region of interest

\emph{spatialrel} : spatial relationship (i.e. ST\_Contains or ST\_Intersect)
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{name}       : name of the table
\end{quote}

\end{fulllineitems}

\index{numpy2sql() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.numpy2sql}\pysiglinewithargsret{\bfcode{numpy2sql}}{\emph{numpyArray}, \emph{dims}}{}
Converts a 1- or 2-D numpy array to an sql friendly array
Do not use with a string array!

\textbf{Parameters}
\begin{quote}

\emph{numpyArray} : numpy array to convert

\emph{dims}       : dimension (1 or 2)
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{array\_sql}  : an sql friendly array
\end{quote}

\end{fulllineitems}

\index{qryCropZone() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.qryCropZone}\pysiglinewithargsret{\bfcode{qryCropZone}}{\emph{granule}, \emph{roi}, \emph{spatialrel}, \emph{inst}, \emph{metaTable}, \emph{srid=4326}}{}
Writes a query to fetch the bounding box of the area that the inst polygon and
image in question intersect.
returns a crop ullr tupple pair in the projection given

\textbf{Parameters}
\begin{quote}

\emph{granule}    : granule name

\emph{roi}        : region of interest file

\emph{spatialrel} : spatial relationship (i.e. ST\_Contains or ST\_Intersect)

\emph{inst}       : instance id (i.e. a 5-digit string)

\emph{metaTable}  : metadata table containing data of images being worked on

\emph{srid}       : srid of desired projection (default WGS84, as this comes out of TC from snap, crop can be done before projection)
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{ullr}       : upper left, lower right tupple pair in the projection given
\end{quote}

\end{fulllineitems}

\index{qryFromFile() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.qryFromFile}\pysiglinewithargsret{\bfcode{qryFromFile}}{\emph{fname}, \emph{path}, \emph{output=False}}{}
Runs a query in the current databse by opening a file - adds the path and 
.sql extension - reading contents to a string and running the query

\textbf{Note:} do not use `\%' in the query b/c it interfers with the pyformat protocol
used by psycopg2

\textbf{Parameters}
\begin{quote}

\emph{fname}  : file name (don't put the sql extension, it's assumed)

\emph{path}   : full path to fname

\emph{output} : make true if you expect/want the query to return results
\end{quote}

\end{fulllineitems}

\index{qryFromText() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.qryFromText}\pysiglinewithargsret{\bfcode{qryFromText}}{\emph{sql}, \emph{output=False}}{}
Runs a query in the current databse by sending an sql string

\textbf{Note:} do not use `\%' in the query b/c it interfers with the pyformat protocol
used by psycopg2. Also be sure to triple quote your string to avoid escaping single quotes.

IF EVER THE Transaction block fails, just conn.rollback(). Try to use pyformat for queries - see dbapi2 (PEP).
You can format the SQL nicely with an online tool - like SQLinForm

\textbf{Parameters}
\begin{quote}

\emph{sql}    : the sql text that you want to send

\emph{output} : make true if you expect/want the query to return results
\end{quote}

\textbf{Returns}
\begin{quote}

The result of the query as a tupple containing a numpy array and the column names as a list (if requested and available)
\end{quote}

\end{fulllineitems}

\index{qryGetInstances() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.qryGetInstances}\pysiglinewithargsret{\bfcode{qryGetInstances}}{\emph{granule}, \emph{roi}, \emph{metaTable}}{}
Writes a query to fetch the instance names that are
associated spatially in the relational table.

\textbf{Parameters}
\begin{quote}

\emph{granule}    : granule name

\emph{roi}        : region of interest file

\emph{metaTable}  : metadata table containing data of images being worked on
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{instances}  : instances id (unique for entire project, i.e. 5-digit string)
\end{quote}

\end{fulllineitems}

\index{qryMaskZone() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.qryMaskZone}\pysiglinewithargsret{\bfcode{qryMaskZone}}{\emph{granule}, \emph{roi}, \emph{srid}, \emph{inst}, \emph{metaTable}}{}
Writes a query to fetch the area the inst polygon in the roi and the image in question intersect. 
This polygon will be used to mask the image.
\begin{quote}

\textbf{Parameters}
\begin{quote}

\emph{granule}    : granule name

\emph{roi}        : region of interest file

\emph{srid}       : srid of desired projection

\emph{inst}       : instance id (i.e. a 5-digit string)

\emph{metaTable}  : metadata table containing data of images being worked on
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{polytext}  :   gml text
\end{quote}
\end{quote}

\end{fulllineitems}

\index{qrySelectFromAvailable() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.qrySelectFromAvailable}\pysiglinewithargsret{\bfcode{qrySelectFromAvailable}}{\emph{roi}, \emph{selectFrom}, \emph{spatialrel}, \emph{srid}}{}
Given a roi table name (with polygons, from/todates), determine the scenes that cover the area
from start (str that looks like iso date) to end (same format).
\begin{description}
\item[{Eventually include criteria:}] \leavevmode
subtype - a single satellite name: ALOS\_AR, RADAR\_AR, RSAT2\_AR (or ANY)        
beam - a beam mode

\end{description}

Returns a list of images+inst - the bounding box

\textbf{Parameters}
\begin{quote}

\emph{roi}        : region of interest table in the database

\emph{spatialrel} : spatial relationship (i.e. ST\_Contains or ST\_Intersect).  Does the image contain the ROI polygon or just intersect with it?

\emph{srid}       : srid of desired projecton

\emph{selectFrom} : table in the database to find the scenes
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{copylist} : a list of image catalog ids

\emph{instimg}  : a list of each instance and the images that correspond
\end{quote}

\end{fulllineitems}

\index{relations2db() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.relations2db}\pysiglinewithargsret{\bfcode{relations2db}}{\emph{roi}, \emph{spatialrel}, \emph{instimg}, \emph{fname=None}, \emph{mode='refresh'}, \emph{export=False}}{}
A function to add or update relational tables that contain the name of an image
and the features that they are spatially related to:
For example:  a table that shows what images intersect with general areas or
a table that lists images that contain ROI polygons

This function runs in create mode or refresh mode
Create - Drops and re-creates the table

Refresh - Adds new data (leaves the old stuff intact)

\textbf{Parameters}
\begin{quote}

\emph{roi}        : region of interest table

\emph{spatialrel} : spatial relationship (i.e. ST\_Contains or ST\_Intersect)

\emph{instimg}    : a list of images that are spatially related to each inst

\emph{fname}      : csv filename if exporting

\emph{mode}       : create or refresh mode

\emph{export}     : If relations should be exported to a csv or not
\end{quote}

\end{fulllineitems}

\index{sql2numpy() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.sql2numpy}\pysiglinewithargsret{\bfcode{sql2numpy}}{\emph{sqlArray}, \emph{dtype='float32'}}{}
Coming from SQL queries, arrays are stored as a list (or list of lists)
Defaults to float32

\textbf{Parameters}
\begin{quote}

\emph{sqlArray} : an sql friendly array

\emph{dtype}    : default type (float32)
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{list}     : list containing the arrays
\end{quote}

\end{fulllineitems}

\index{updateFromArchive() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.updateFromArchive}\pysiglinewithargsret{\bfcode{updateFromArchive}}{\emph{archDir}}{}
Goes to CIS Archive metadata shapefiles and (re)creates and updates tblArchive in the connected database
tblArchive then represents all the image files that CIS has (in theory)
The first thing this script does is define the table - this is done from an sql file and contains the required SRID
Then it uses ogr2ogr to upload each shp in the archDir 
The script looks for the {\color{red}\bfseries{}*}.last files to know which files are the most current (these need to be updated)

Can be extended to import from other archives (In the long term - PDC?)

\textbf{Parameters}
\begin{quote}

\emph{archDir} : archive directory
\end{quote}

\end{fulllineitems}

\index{updateROI() (Database.Database method)}

\begin{fulllineitems}
\phantomsection\label{code:Database.Database.updateROI}\pysiglinewithargsret{\bfcode{updateROI}}{\emph{inFile}, \emph{srid}, \emph{wdir}, \emph{ogr=False}}{}
This function will update an ROI (Region Of Interest) table in the database. It has a prescribed format
It will take the shapefile named inFile and update the database with the info

Note that this will overwrite any table named \emph{inFile} in the database

The generated table will include a column \emph{inst} - a unique identifier created by 
concatenating obj and instid

\textbf{Parameters}
\begin{quote}

\emph{inFile}   : Basename of a shapefile (becomes the ROI table name too)

\emph{srid}     : srid of desired projection

\emph{wdir}     : Full path to directory containing ROI (NOT path to ROI itself, just the directory containing it)
\end{quote}

\textbf{Required in ROI (In shp attribute table)}
\begin{quote}

\emph{obj}      - The id or name of an object/polygon that defines a region of interest. Very systematic, no spaces.

\emph{instid}   - A number to distinguish repetitions of each obj in time or space.  For example an ROI that occurs several summers would have several instids.

\emph{fromdate} - A valid iso time denoting the start of the ROI - can be blank if imgref is used

\emph{todate}   - A valid iso time denoting the start of the ROI - can be blank if imgref is used
\end{quote}

\textbf{Optional in ROI (in shp attribute table)}
\begin{quote}

\emph{imgref}   - A reference image dimage name (for a given ROI) - this can be provided in place of datefrom and dateto

\emph{name}     - A name for each obj (Area51\_1950s, Target7, Ayles)

\emph{comment}  - A comment field

Any other field can be added...
\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\section{Utilities}
\label{code:module-Util}\label{code:utilities}\index{Util (module)}
\textbf{util.py}

This module contains miscellaneous code that helps siglib work with directories, 
zip files, clean up intermediate files and so on.

\textbf{Created on} Tue Feb 12 20:04:11 2013 \textbf{@author:} Cindy Lopes
\textbf{Modified on} Sat Nov 23 14:49:18 2013 \textbf{@reason:} Added writeIssueFile and compareIssueFiles \textbf{@author:} Sougal Bouh Ali
\textbf{Modified on} Sat Nov 30 15:37:22 2013 \textbf{@reason:} Redesigned getFilname, getZipRoot and unZip \textbf{@author:} Sougal Bouh Ali
\textbf{Modified on} Wed May 23 14:41:40 2018 \textbf{@reason:} Added logging functionality \textbf{@author:} Cameron Fitzpatrick
\index{az() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.az}\pysiglinewithargsret{\code{Util.}\bfcode{az}}{\emph{pt1}, \emph{pt2}}{}
Calculates the great circle initial azimuth between two points
in dd.ddd format. 
This formula assumes a spherical earth.  Use Vincenty's formulae
for better precision

\href{https://en.wikipedia.org/wiki/Azimuth}{https://en.wikipedia.org/wiki/Azimuth}
\href{https://en.wikipedia.org/wiki/Vincenty\%27s\_formulae}{https://en.wikipedia.org/wiki/Vincenty\%27s\_formulae}

\textbf{Parameters:}
\begin{quote}

\emph{pt1} : point from (tuple of lon and lat)

\emph{pt2} : point to (tuple of lon and lat)
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{az}  : azimuth from North in degrees
\end{quote}

\end{fulllineitems}

\index{cleartree() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.cleartree}\pysiglinewithargsret{\code{Util.}\bfcode{cleartree}}{\emph{dirname}}{}
Delet all files in a certain path

\textbf{Parameters}
\begin{quote}

\emph{dirname} :
\end{quote}

\end{fulllineitems}

\index{copyfiles() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.copyfiles}\pysiglinewithargsret{\code{Util.}\bfcode{copyfiles}}{\emph{self}, \emph{copylist}, \emph{wrkdir}, \emph{fname=None}, \emph{export=False}, \emph{loghandler=None}}{}
Copies files from a local archive. If file could not be found, check that the 
drive mapping is correct (above).

\textbf{Parameters}
\begin{quote}

\emph{copylist} : a list of images + inst

\emph{wrkdir}   : working directory

\emph{fname}    : Filename if exporting copylist as txt

\emph{export}   : True if want to export copylist as txt
\end{quote}

\end{fulllineitems}

\index{deltree() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.deltree}\pysiglinewithargsret{\code{Util.}\bfcode{deltree}}{\emph{dirname}}{}
Delete all the files and sub-directories in a certain path

\textbf{Parameters}
\begin{quote}

\emph{dirname}   :
\end{quote}

\end{fulllineitems}

\index{getFilename() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.getFilename}\pysiglinewithargsret{\code{Util.}\bfcode{getFilename}}{\emph{zipname}, \emph{unzipdir}, \emph{loghandler=None}}{}
Given the name of a zipfile, return the name of the image,
the file name, and the corresponding sensor/platform (satellite).

\textbf{Parameters}
\begin{quote}

\emph{zipname}  : The basename of the zip file you are working with

\emph{unzipdir} : Where the zipfile will unzip to (find out with getZipRoot)
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{fname}    :  The file name that corresponds to the image

\emph{imgname}  : The name of the image (the basename, sans extension)

\emph{sattype}  : The type of satellite/image format this file represents
\end{quote}

\end{fulllineitems}

\index{getPowerScale() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.getPowerScale}\pysiglinewithargsret{\code{Util.}\bfcode{getPowerScale}}{\emph{dB}}{}
Convert a SAR backscatter value from the log dB scale to the linear power scale

\textbf{Note:} dB must be a scalar or an array of scalars

\textbf{Parameters}
\begin{quote}

\emph{dB}    : backscatter in dB units
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{power} : backscatter in power units
\end{quote}

\end{fulllineitems}

\index{getZipRoot() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.getZipRoot}\pysiglinewithargsret{\code{Util.}\bfcode{getZipRoot}}{\emph{zip\_file}, \emph{tmpDir}}{}
Looks into a zipfile and determines if the contents will unzip into a subdirectory
(named for the zipfile); or a sub-subdirectory; or no directory at all (loose files)

Run this function to determine where the files will be unzipped to. If the files are in
the immediate subfolder, then that is what is required.

Returns the unzipdir (where the files will -or should- go) and zipname (basename of the zipfile)

\textbf{Parameters}
\begin{quote}

\emph{zip\_file} : full path, name and ext of a zip file

\emph{tmpDir}   : this is the path to the directory where you are working with this file (the path of the zip\_file - or wrkdir)
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{unzipdir} : the directory where the zip file will/should unzip to

\emph{zipname}  : basename of the zip file AND/OR the name of the folder where the image files are
\end{quote}

\end{fulllineitems}

\index{getdBScale() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.getdBScale}\pysiglinewithargsret{\code{Util.}\bfcode{getdBScale}}{\emph{power}}{}
Convert a SAR backscatter value from the linear power scale to the log dB scale

\textbf{Note:} power must be a scalar or an array of scalars,negative powers will throw back NaN.

\textbf{Parameters}
\begin{quote}

\emph{power} : backscatter in power units
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{dB}    : backscatter in dB units
\end{quote}

\end{fulllineitems}

\index{llur2ullr() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.llur2ullr}\pysiglinewithargsret{\code{Util.}\bfcode{llur2ullr}}{\emph{llur}}{}
a function that returns:
upperleft, lower right when given...
lowerleft, upper right
a list of tupples {[}(x,y),(x,y){]}

Note - this will disappoint if proj is transformed (before or after)

\textbf{Parameters}
\begin{quote}

\emph{llur} : a list of tupples {[}(x,y),(x,y){]} corresponding to lower left, upper right corners of a bounding box
\end{quote}

\end{fulllineitems}

\index{reprojSHP() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.reprojSHP}\pysiglinewithargsret{\code{Util.}\bfcode{reprojSHP}}{\emph{in\_shp}, \emph{vectdir}, \emph{proj}, \emph{projdir}}{}
Opens a shapefile, saves it as a new shapefile in the same directory
that is reprojected to the projection wkt provided.

\textbf{Note:} this could be expanded to get polyline data from polygon data
for masking lines (not areas) ogr2ogr -nlt MULTILINESTRING

\textbf{Parameters}
\begin{quote}

\emph{in\_shp}  :

\emph{vectdir} :

\emph{proj}    :

\emph{projdir} :
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{out\_shp} : name of the proper shapefile
\end{quote}

\end{fulllineitems}

\index{ullr2llur() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.ullr2llur}\pysiglinewithargsret{\code{Util.}\bfcode{ullr2llur}}{\emph{ullr}}{}
a function that returns:
lowerleft, upper right when given...
upperleft, lower right
a list of tupples {[}(x,y),(x,y){]}

Note - this will disappoint if proj is transformed (before or after)

\textbf{Parameters}
\begin{quote}

\emph{ullr} : a list of tupples {[}(x,y),(x,y){]} corresponding to upper right, lower left corners of a bounding box
\end{quote}

\end{fulllineitems}

\index{unZip() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.unZip}\pysiglinewithargsret{\code{Util.}\bfcode{unZip}}{\emph{zip\_file}, \emph{unzipdir}, \emph{ext='all'}}{}
Unzips the zip\_file to unzipdir with python's zipfile module.

``ext'' is a keyword that defaults to all files, but can be set
to just extract a leader file L or xml for example.

\textbf{Parameters}
\begin{quote}

\emph{zip\_file} : Name of a zip file - with extension
\begin{quote}

\emph{unzipdir} : Directory to unzip to
\end{quote}
\end{quote}

\textbf{Optional}
\begin{quote}

\emph{ext}      : `all' or a specific ext as required
\end{quote}

\end{fulllineitems}

\index{wkt2shp() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.wkt2shp}\pysiglinewithargsret{\code{Util.}\bfcode{wkt2shp}}{\emph{shpname}, \emph{vectdir}, \emph{proj}, \emph{projdir}, \emph{wkt}}{}
Takes a polygon defined by well-known-text and a projection name and outputs
a shapefile into the current directory

\textbf{Parameters}
\begin{quote}

\emph{shpname} :

\emph{vectdir} :

\emph{proj}    :

\emph{projdir} :

\emph{wkt}     :
\end{quote}

\end{fulllineitems}

\index{wktpoly2pts() (in module Util)}

\begin{fulllineitems}
\phantomsection\label{code:Util.wktpoly2pts}\pysiglinewithargsret{\code{Util.}\bfcode{wktpoly2pts}}{\emph{wkt}, \emph{bbox=False}}{}
Converts a Well-known Text string for a polygon into a series of tuples that
correspond to the upper left, upper right, lower right and lower left corners

This works with lon/lat rectangles.

If you have a polygon that is not a rectangle, set bbox to True and the 
bounding box corners will be returned

Note that for rectangles in unprojected coordinates (lon/lat deg), this is 
slightly different from ullr or llur (elsewhere in this project) which are 
derived from bounding boxes of projected coordinates

\textbf{Parameters}
\begin{quote}

\emph{wkt}         : a well-known text string for a polygon
\end{quote}

\textbf{Returns}
\begin{quote}

\emph{ul,ur,lr,ll} : a list of the four corners
\end{quote}

\end{fulllineitems}



\renewcommand{\indexname}{Python Module Index}
\begin{theindex}
\def\bigletter#1{{\Large\sffamily#1}\nopagebreak\vspace{1mm}}
\bigletter{d}
\item {\texttt{Database}}, \pageref{code:module-Database}
\indexspace
\bigletter{i}
\item {\texttt{Image}}, \pageref{code:module-Image}
\indexspace
\bigletter{m}
\item {\texttt{Metadata}}, \pageref{code:module-Metadata}
\indexspace
\bigletter{s}
\item {\texttt{SigLib}}, \pageref{code:module-SigLib}
\indexspace
\bigletter{u}
\item {\texttt{Util}}, \pageref{code:module-Util}
\end{theindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}
